<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>In-N-Out: Lifting 2D Diffusion Prior for 3D Object Removal via Tuning-Free Latents Alignment</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link rel="icon" type="image/png" href="assets/images/logo.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">In-N-Out: Lifting 2D Diffusion Prior for 3D Object Removal via Tuning-Free Latents Alignment</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://timmy11hu.github.io/" target="_blank">Dongting Hu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://huan-fu.github.io/" target="_blank">Huan Fu</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://cr-gjx.github.io/" target="_blank">Jiaxian Guo</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://sites.google.com/view/liuhua-peng" target="_blank">Liuhua Peng</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=lzyHiI8AAAAJ&hl=en" target="_blank">Tingjin Chu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://fengliu90.github.io/" target="_blank">Feng Liu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://tongliang-liu.github.io/" target="_blank">Tongliang Liu</a><sup>4,5</sup>,</span>
              <span class="author-block">
                <a href="https://mingming-gong.github.io/" target="_blank">Mingming Gong</a><sup>1,5</sup></span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup> The University of Melbourne</span> 
                    <span class="author-block"><sup>2</sup> Alibaba</span>
                    <span class="author-block"><sup>3</sup> Google Research</span>
                    <span class="author-block"><sup>4</sup> The University of Sydney</span>
                    <span class="author-block"><sup>5</sup> MBZUAI</span>
                  </div>
                  <div class="is-size-5 publication-authors">  
                    <span class="eql-cntrb">NeurIPS, 2024</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://openreview.net/pdf?id=gffaYDu9mM" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/timmy11hu/3DOR" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser -->
<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
        <div class="row is-centered has-text-centered">
    <div style="display: flex; justify-content: space-around; flex-wrap: wrap; margin-top: -20px; margin-bottom: -100px;">
        <div class="row">
            <div class="content has-text-justified">
                <img src="assets/images/abstract.png" class="img-responsive" alt="overview"><br>
            </div>
          </div>
  </div>
  </div>
  </div>
  </div>
  <br><br>
  <!-- <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div> -->
</section>
<!-- End teaser -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Neural representations for 3D scenes have made substantial advancements recently,
             yet object removal remains a challenging yet practical issue,
              due to the absence of multi-view supervision over occluded areas.
              Diffusion Models (DMs), trained on extensive 2D images, show diverse and high-fidelity generative capabilities in the 2D domain.
               However, due to not being specifically trained on 3D data,
                their application to multi-view data often exacerbates inconsistency,
                 hence impacting the overall quality of the 3D output.
                  To address these issues, we introduce ``In-N-Out'', a novel approach that begins by <u>in</u>painting a prior,
                   i.e., the occluded area from a single view using DMs,
                    followed by <u>out</u>stretching it to create multi-view inpaintings via latents alignments.
                     Our analysis identifies that the variability in DMs' outputs mainly arises from initially sampled latents and intermediate latents predicted in the denoising process.
                      We <em>explicitly</em> align of <em>initial</em> latents using a Neural Radiance Field (NeRF) to establish a consistent foundational structure in the inpainted area,
                        complemented by an <em>implicit</em> alignment of <em>intermediate</em> latents through cross-view attention during the denoising phases, enhancing appearance consistency across views.
                         To further enhance rendering results, we apply a patch-based hybrid loss to optimize NeRF.
                          We demonstrate that our techniques effectively mitigate the challenges posed by inconsistencies in DMs and substantially improve the fidelity and coherence of inpainted 3D representations. 
            </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<!-- Rendering Results -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-centered has-text-centered">
      <h2 class="title is-3">Rendering Results</h2>
      <div class="video-row">
        <div class="video-container">
            <p class="video-caption">Original Input</p>
            <video class="video-item" autoplay controls muted loop>
                <source src="assets/videos/base/t6.mp4" type="video/mp4">
            </video>
        </div>
        <div class="video-container">
            <p class="video-caption">SPInNeRF (multi-view)</p>
            <video class="video-item" autoplay controls muted loop>
                <source src="assets/videos/spinnerf/t6.mp4" type="video/mp4">
            </video>
        </div>
        <div class="video-container">
            <p class="video-caption">InFusion (single-view)</p>
            <video class="video-item" autoplay controls muted loop>
                <source src="assets/videos/infusion/t6.mp4" type="video/mp4">
            </video>
        </div>
        <div class="video-container">
            <p class="video-caption">Ours</p>
            <video class="video-item" autoplay controls muted loop>
                <source src="assets/videos/ours/t6.mp4" type="video/mp4">
            </video>
        </div>
    </div>

    <div class="video-row">
      <div class="video-container">
          <video class="video-item" autoplay controls muted loop>
              <source src="assets/videos/base/book.mp4" type="video/mp4">
          </video>
      </div>
      <div class="video-container">
          <video class="video-item" autoplay controls muted loop>
              <source src="assets/videos/spinnerf/book.mp4" type="video/mp4">
          </video>
      </div>
      <div class="video-container">
          <video class="video-item" autoplay controls muted loop>
              <source src="assets/videos/infusion/book.mp4" type="video/mp4">
          </video>
      </div>
      <div class="video-container">
          <video class="video-item" autoplay controls muted loop>
              <source src="assets/videos/ours/book.mp4" type="video/mp4">
          </video>
      </div>
  </div>

  <div class="video-row">
    <div class="video-container">
        <video class="video-item" autoplay controls muted loop>
            <source src="assets/videos/base/t3.mp4" type="video/mp4">
        </video>
    </div>
    <div class="video-container">
        <video class="video-item" autoplay controls muted loop>
            <source src="assets/videos/spinnerf/t3.mp4" type="video/mp4">
        </video>
    </div>
    <div class="video-container">
        <video class="video-item" autoplay controls muted loop>
            <source src="assets/videos/infusion/t3.mp4" type="video/mp4">
        </video>
    </div>
    <div class="video-container">
        <video class="video-item" autoplay controls muted loop>
            <source src="assets/videos/ours/t3.mp4" type="video/mp4">
        </video>
    </div>
</div>

<div class="video-row">
  <div class="video-container">
      <video class="video-item" autoplay controls muted loop>
          <source src="assets/videos/base/trash.mp4" type="video/mp4">
      </video>
  </div>
  <div class="video-container">
      <video class="video-item" autoplay controls muted loop>
          <source src="assets/videos/spinnerf/trash.mp4" type="video/mp4">
      </video>
  </div>
  <div class="video-container">
      <video class="video-item" autoplay controls muted loop>
          <source src="assets/videos/infusion/trash.mp4" type="video/mp4">
      </video>
  </div>
  <div class="video-container">
      <video class="video-item" autoplay controls muted loop>
          <source src="assets/videos/ours/trash.mp4" type="video/mp4">
      </video>
  </div>
</div>

<div class="video-row">
  <div class="video-container">
      <video class="video-item" autoplay controls muted loop>
          <source src="assets/videos/base/t5.mp4" type="video/mp4">
      </video>
  </div>
  <div class="video-container">
      <video class="video-item" autoplay controls muted loop>
          <source src="assets/videos/spinnerf/t5.mp4" type="video/mp4">
      </video>
  </div>
  <div class="video-container">
      <video class="video-item" autoplay controls muted loop>
          <source src="assets/videos/infusion/t5.mp4" type="video/mp4">
      </video>
  </div>
  <div class="video-container">
      <video class="video-item" autoplay controls muted loop>
          <source src="assets/videos/ours/t5.mp4" type="video/mp4">
      </video>
  </div>
</div>
    </div>
  </div>
</section>
<!-- End Rendering Results-->



<!-- Method -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-centered has-text-centered is-max-desktop">
      <h2 class="title">Method</h2>

      <!-- General Description -->
      <p class="description has-text-left">
        Given a set of multi-view training images <span>&#123;I<sub>i</sub>&#125;</span> from a scene, 
        with corresponding masks <span>&#123;M<sub>i</sub>&#125;</span> indicating unwanted objects in each frame, 
        our approach aims to generate a consistently inpainted training set. 
        These inpainted images are then used to supervise NeRF. 
        The method is structured into three key stages:
      </p>

      <!-- Stage 1 -->
      <div class="row has-text-left">
        <p class="content">
          <strong>Stage 1:</strong> Pretrain a NeRF model (<span>&#x3C6;</span>) using the original images 
          <span>&#123;I<sub>i</sub>&#125;</span>, the masks <span>&#123;M<sub>i</sub>&#125;</span>, 
          and a sampled inpainted prior <span>I<sub>p</sub></span>, which provides a rough 
          hallucination of the inpainting features.
        </p>
      </div>

      <!-- Stage 2 -->
      <div class="row has-text-left">
        <p class="content">
          <strong>Stage 2:</strong> Use the pretrained NeRF (<span>&#x3C6;</span>) to inpaint additional views 
          <span>&#123;I<sub>i</sub> | i &#8800; p, i = 1, &#x2026;, N&#125;</span>. This is achieved by aligning both explicit 
          and implicit latents (<em>ELA</em> and <em>ILA</em>), conditioned on the inpainting prior <span>I<sub>p</sub></span>. 
        </p>
      </div>

      <!-- Stage 3 -->
      <div class="row has-text-left">
        <p class="content">
          <strong>Stage 3:</strong> Using the inpainted image set 
          <span>&#123;I<sub>i</sub>&#125;</span>, optimize the NeRF model (<span>&#x3C6;</span>) with 
          a patch-based hybrid loss to distill multi-view supervision.
        </p>
      </div>

      <!-- General Description -->
      <p class="description has-text-left">
        Please refer to our paper for more details.
      </p>
    </section>

    <section class="hero is-small">
      <div class="hero-body">
        <div class="container is-centered has-text-centered is-max-desktop">
      <div class="row">
        <div class="content has-text-justified">
            <img src="assets/images/method1.png" class="img-responsive" alt="overview"><br>
        </div>
      </div>

      <div class="row">
        <div class="content has-text-justified">
            <img src="assets/images/method2.png" class="img-responsive" alt="overview"><br>
        </div>
      </div>
        
      </div>
    </div>
  </section>
<!--End method -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @inproceedings{hu2024innout,
          title     = {In-N-Out: Lifting 2D Diffusion Prior for 3D Object Removal via Tuning-Free Latents Alignment},
          author    = {Dongting Hu and Huan Fu and Jianxian Guo and Liuhua Peng and Tingjin Chu and Feng Liu and Tongliang Liu and Mingming Gong},
          booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
          year      = {2024},
        }
        
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This website is borrowed from <a href="https://diffusion-tokenflow.github.io/" target="_blank">here</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
